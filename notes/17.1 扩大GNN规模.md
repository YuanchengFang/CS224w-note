Scaling up graph neural networks to large graphs

#### Standard SGD cannot effectively train GNNs

The sampled nodes in mini-batch tend to be isolated from each other. They cannot do message passing.

#### Full-batch is not feasible for a large graph

For a large graph, the entire graph and the features cannot be loaded on GPU.

#### Some methods for scaling up GNNs

- Message-passing over small subgraphs in each **mini-batch**. i.e. Neighbor sampling and Cluster-GCN
- Simplify a GNN into feature-preprocessing operation. i.e. Simplified GCN